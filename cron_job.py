import os
import time
import json
import numpy as np
import pandas as pd
import yfinance as yf
import gspread
import pytz
from datetime import datetime
from google.oauth2.service_account import Credentials

# -----------------------------------------------------------------
# 1. åˆå§‹åŒ–èˆ‡é€£ç·š
# -----------------------------------------------------------------
# --- ä¿®æ”¹ init_gspread å‡½æ•¸ ---
def init_gspread():
    creds_json = os.environ.get("GCP_SERVICE_ACCOUNT_JSON")
    if not creds_json:
        # åœ¨ Streamlit ç’°å¢ƒä¸­ï¼Œå˜—è©¦å¾ st.secrets æŠ“å–
        import streamlit as st
        creds_json = st.secrets.get("GCP_SERVICE_ACCOUNT_JSON")
        
    if not creds_json:
        raise ValueError("ç’°å¢ƒè®Šæ•¸ GCP_SERVICE_ACCOUNT_JSON ç¼ºå¤±")
    
    info = json.loads(creds_json)
    scope = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
    # âš ï¸ é€™è£¡æ”¹ç”¨ from_service_account_info
    creds = Credentials.from_service_account_info(info, scopes=scope)
    return gspread.authorize(creds)
# -----------------------------------------------------------------
# 2. æ•¸æ“šå¼•æ“ï¼šå¢åŠ  RSI è¨ˆç®—
# -----------------------------------------------------------------
def calculate_rsi(df, periods=14):
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=periods).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=periods).mean()
    rs = gain / (loss + 1e-9)
    return 100 - (100 / (1 + rs))

def fetch_comprehensive_data(symbol):
    raw_s = str(symbol).strip().upper()
    search_list = [raw_s]
    if not (raw_s.endswith(".TW") or raw_s.endswith(".TWO")):
        search_list = [f"{raw_s}.TW", f"{raw_s}.TWO"]

    for s in search_list:
        try:
            df = yf.download(s, period="2y", interval="1d", auto_adjust=True, progress=False)
            if df is not None and not df.empty and len(df) > 40:
                if isinstance(df.columns, pd.MultiIndex): 
                    df.columns = df.columns.get_level_values(0)
                df = df[['Open', 'High', 'Low', 'Close', 'Volume']].astype(float)
                return df, s
        except: continue
    return None, raw_s

def fetch_market_context():
    try:
        mkt = yf.download("^TWII", period="60d", interval="1d", auto_adjust=True, progress=False)
        if isinstance(mkt.columns, pd.MultiIndex): mkt.columns = mkt.columns.get_level_values(0)
        return mkt
    except: return None

# -----------------------------------------------------------------
# 3. é æ¸¬ä¹‹ç¥æ ¸å¿ƒï¼šå°ˆå®¶ç´šæ¬Šç­–å¤§è…¦ (æ•¸æ“šæ ¼å¼å„ªåŒ–ç‰ˆ)
# -----------------------------------------------------------------
def god_mode_engine(df, symbol, mkt_df):
    last = df.iloc[-1]
    curr_p = float(last['Close'])
    
    # [A] å¤§ç›¤ä¿®æ­£å› å­
    mkt_trend, beta = 1.0, 1.0
    if mkt_df is not None:
        m_returns = mkt_df['Close'].pct_change().dropna()
        s_returns = df['Close'].pct_change().dropna()
        common = m_returns.index.intersection(s_returns.index)
        if len(common) > 10:
            beta = np.cov(s_returns[common], m_returns[common])[0,1] / (np.var(m_returns[common]) + 1e-9)
        mkt_ma20 = mkt_df['Close'].rolling(20).mean().iloc[-1]
        mkt_trend = 1.03 if mkt_df['Close'].iloc[-1] > mkt_ma20 else 0.97

    # [B] æŒ‡æ¨™è¨ˆç®—èˆ‡ä¹–é›¢ç‡
    bias_list = []
    for n in [5, 10, 15, 20]:
        ma = df['Close'].rolling(n).mean().iloc[-1]
        b_val = round(((curr_p - ma) / (ma + 1e-9)) * 100, 2)
        bias_list.append(float(b_val)) # å¼·åˆ¶è½‰ç‚º float ç¢ºä¿ Sheets è­˜åˆ¥
    
    # [C] æˆ°ç•¥æ°´ä½ (30D) - ä¿®æ­£å¾Œçš„åƒ¹æ ¼è¨ˆç®—é‚è¼¯
    periods = [5, 10, 15, 20, 25, 30]
    buy_levels, sell_levels, resist_levels = [], [], []
    for p in periods:
        sub = df.tail(p)
        ma, std = sub['Close'].mean(), sub['Close'].std()
        
        # æ”¯æ’/å£“åŠ›ä½è¨ˆç®— (ç¢ºä¿è¼¸å‡ºæ˜¯ç´”æ•¸å­—åƒ¹æ ¼)
        b_p = (ma - (std * 1.5)) * 0.4 + sub['Low'].min() * 0.6
        s_p = ma + (std * 1.3)
        r_p = max(sub['High'].max(), ma + (std * 2.1))
        
        buy_levels.append(float(round(b_p, 2)))
        sell_levels.append(float(round(s_p, 2)))
        resist_levels.append(float(round(r_p, 2)))
    
    strategic_data = buy_levels + sell_levels + resist_levels

    # [D] 7å¤©é æ¸¬è»Œè·¡
    np.random.seed(int(time.time()))
    f_vol = df['Close'].pct_change().tail(20).std()
    drift = (df['Close'].pct_change().tail(10).mean() * mkt_trend) - (bias_list[3] * 0.005)
    
    sim_paths = []
    for _ in range(800):
        path = [curr_p]
        for _ in range(7):
            change = np.random.normal(drift, f_vol * (1 + abs(beta-1)))
            path.append(path[-1] * (1 + change))
        sim_paths.append(path[1:])
    
    pred_7d_list = np.mean(sim_paths, axis=0)
    pred_path_str = ",".join([str(round(float(x), 2)) for x in pred_7d_list])

    # [E] å°ˆå®¶ç´šæŒ‡æ¨™ç¶­åº¦ (AF-AI)
    atr = (df['High'].tail(14).max() - df['Low'].tail(14).min()) / 14
    vol_ratio = df['Volume'].iloc[-1] / (df['Volume'].tail(20).mean() + 1e-9)
    
    # ç›ˆè™§æ¯”ç©©å®šåŒ–è¨ˆç®—
    upside = pred_7d_list.max() - curr_p
    downside = curr_p - buy_levels[0]
    rr_ratio = round(float(upside / (abs(downside) + 1e-9)), 2)
    
    rsi_series = calculate_rsi(df)
    rsi_val = float(rsi_series.iloc[-1]) if not rsi_series.empty else 50.0
    
    sentiment = "å†·éœ"
    if bias_list[0] > 7 or rsi_val > 75: sentiment = "éç†±"
    elif bias_list[0] < -7 or rsi_val < 25: sentiment = "ææ…Œ"
    
    expert_data = [float(round(atr, 2)), float(round(vol_ratio, 2)), float(rr_ratio), sentiment]

    # [F] AI ç¶œåˆè¨ºæ–·å ±å‘Š (AA æ¬„)
    chip_status = "è³‡é‡‘æµå…¥" if (df['Close'].iloc[-1] > df['Open'].iloc[-1] and vol_ratio > 1.2) else "ç±Œç¢¼ç©©å®š"
    mkt_text = "çœ‹å¤š" if mkt_trend > 1 else "ä¿å®ˆ"
    best_inds = "MACD, Bias, Bollinger" if abs(bias_list[0]) > 3 else "MA, RSI, KDJ"
    
    insight = (f"ã€Oracle è¨ºæ–·ã€‘{symbol} ç›®å‰è¶¨å‹¢å{chip_status}ã€‚å¤§ç›¤ç’°å¢ƒ{mkt_text}(Beta:{beta:.2f})ã€‚ "
               f"AI ä¾è‚¡æ€§é¸æ“‡æœ€ä½³æŒ‡æ¨™ï¼š{best_inds}ã€‚ 5æ—¥ä¹–é›¢ {bias_list[0]}%ï¼Œ"
               f"ç›ˆè™§æ¯”è©•ä¼°ç‚º {rr_ratio}ã€‚å»ºè­°é—œæ³¨ 5D æ”¯æ’ä½ {buy_levels[0]}ã€‚")

    return float(round(pred_7d_list[0], 2)), pred_path_str, insight, bias_list, strategic_data, expert_data

# -----------------------------------------------------------------
# 4. å…¨å±€è‡ªå‹•åŒ–åŒæ­¥é‚è¼¯ (äº¤æ˜“æ—¥è‡ªå‹•å°é½Šä¿®æ­£ç‰ˆ)
# -----------------------------------------------------------------
def run_daily_sync():
    try:
        tw_tz = pytz.timezone('Asia/Taipei')
        now = datetime.now(tw_tz)
        
        # [æ™‚é–“é–å·²è¨»è§£] æ–¹ä¾¿å‡Œæ™¨æˆ–é€±æœ«æ‰‹å‹•æ¸¬è©¦ï¼Œæ­£å¼ä¸Šç·šå¾Œå¯è§£é™¤è¨»è§£
          if now.hour < 14 or (now.hour == 14 and now.minute < 30):
              print(f"â³ ç•¶å‰æ™‚é–“ {now.strftime('%H:%M')}ï¼Œæœªé” 14:30ï¼Œè·³éã€‚")
              return

        client = init_gspread()
        sh = client.open("users")
        ws_p = sh.worksheet("predictions")
        ws_w = sh.worksheet("watchlist")
        
        # 1. æŠ“å–æ‰€æœ‰ä½¿ç”¨è€…çš„ Watchlist ä¸¦å»é‡
        all_watchlists = ws_w.get_all_values()[1:]
        unique_symbols = set(str(row[1]).strip().upper() for row in all_watchlists if len(row) >= 2 and row[1])
        
        if not unique_symbols:
            print("âŒ Watchlist ç‚ºç©ºï¼Œç„¡é ˆåˆ†æã€‚")
            return

        # ç²å– predictions è¡¨ç›®å‰æ‰€æœ‰æ•¸æ“šï¼Œç”¨æ–¼æª¢æŸ¥æ˜¯å¦é‡è¤‡
        existing_rows = ws_p.get_all_values()

        print(f"ğŸš€ å•Ÿå‹• Oracle å¼•æ“ï¼šé è¨ˆåˆ†æ {len(unique_symbols)} æ”¯è‚¡ç¥¨...")
        mkt_df = fetch_market_context()

        for symbol in unique_symbols:
            try:
                df, f_id = fetch_comprehensive_data(symbol)
                if df is None:
                    print(f"â“ ç„¡æ³•ç²å– {symbol} æ•¸æ“šï¼Œè·³éã€‚")
                    continue
                
                # [æ ¸å¿ƒä¿®æ­£] ä½¿ç”¨ K ç·šæ•¸æ“šæœ€å¾Œä¸€å¤©çš„æ—¥æœŸä½œç‚ºå­˜æª”åŸºæº–æ—¥ (ä¾‹å¦‚ 2026-01-16)
                data_date = df.index[-1].strftime("%Y-%m-%d")
                
                # 2. ç²¾æº–å»é‡ï¼šæª¢æŸ¥è©²è‚¡ç¥¨åœ¨ã€Œè©²äº¤æ˜“æ—¥ã€æ˜¯å¦å·²ç¶“æœ‰åˆ†æçµæœ
                is_done = False
                for row in existing_rows:
                    if len(row) >= 2 and row[0] == data_date and row[1] == f_id:
                        is_done = True
                        break
                
                if is_done:
                    print(f"â© {f_id} æ–¼ {data_date} çš„åˆ†æå·²å­˜åœ¨ï¼Œè·³éã€‚")
                    continue
                
                # åŸ·è¡Œé æ¸¬ä¹‹ç¥å¤§è…¦ (å›å‚³åŒ…å« expert_data)
                p_next, path_str, insight, biases, s_data, e_data = god_mode_engine(df, f_id, mkt_df)
                
                # 3. æº–å‚™ä¸Šå‚³æ•¸æ“šåˆ— (A-AI æ¬„ï¼Œç¸½è¨ˆ 35 æ¬„)
                # ä½¿ç”¨ data_date ç¢ºä¿æ—¥æœŸæ¨™ç±¤èˆ‡æ•¸æ“šä¾†æºä¸€è‡´
                upload_row = [
                    data_date, f_id, p_next, round(p_next*0.985, 2), round(p_next*1.015, 2), "å¾…æ”¶ç›¤æ›´æ–°"
                ] + s_data + [0] + [path_str, insight] + biases + e_data
                
                ws_p.append_row(upload_row)
                print(f"ğŸ”® {f_id} åˆ†æå®Œæˆ (åŸºæº–æ—¥: {data_date})ã€‚")
                
                # åŒæ­¥æ›´æ–°æœ¬åœ°æ¯”å°æ¸…å–®ï¼Œé¿å…åŒä¸€æ‰¹æ¬¡å…§æ„å¤–é‡è¤‡
                existing_rows.append(upload_row)
                
                # é€Ÿç‡é™åˆ¶ï¼Œä¿è­· Google Sheets API
                time.sleep(3) 

            except Exception as e:
                print(f"âŒ åˆ†æ {symbol} å¤±æ•—: {e}")

    except Exception as e:
        print(f"ğŸ’¥ æ ¸å¿ƒé‚è¼¯ç™¼ç”Ÿç•°å¸¸: {e}")

if __name__ == "__main__":
    run_daily_sync()

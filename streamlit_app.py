import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
import gspread
from google.oauth2.service_account import Credentials
import json
import time
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta

# --- 1. é…ç½®èˆ‡ UI è¦–è¦º (ä¿®å¾©é»‘å±å…¼å®¹æ€§ç‰ˆæœ¬) ---
st.set_page_config(page_title="StockAI å°è‚¡å…¨èƒ½çµ‚ç«¯", layout="wide", initial_sidebar_state="collapsed")

# è¨ºæ–·é»ï¼šå¦‚æœåœ¨ç¶²é æœ€ä¸Šæ–¹çœ‹åˆ°é€™è¡Œå­—ï¼Œä»£è¡¨ Section 1 æ­£å¸¸
st.caption("ğŸš€ ç³»çµ±æ ¸å¿ƒå•Ÿå‹•ä¸­... è‹¥é•·æ™‚é–“é»‘å±è«‹æª¢æŸ¥ Secrets é…ç½®")

st.markdown("""
    <style>
    /* ç¢ºä¿åŸºç¤èƒŒæ™¯é¡è‰²å„ªå…ˆè¼‰å…¥ */
    .stApp { background-color: #0E1117 !important; }
    
    /* ç§»é™¤å¯èƒ½å°è‡´é–æ­»çš„éš±è—å…ƒä»¶ä»£ç¢¼ï¼Œæ”¹ç”¨æ¨™æº–æ–¹å¼ */
    [data-testid="stSidebar"] { background-color: #161B22; }
    
    label, p, span, .stMarkdown, .stCaption { color: #FFFFFF !important; font-weight: 800 !important; }
    
    /* å¼·åŒ–è¼¸å…¥æ¡†é¡¯ç¤ºï¼Œé˜²æ­¢é»‘åº•é»‘å­— */
    input { 
        color: #000000 !important; 
        background-color: #FFFFFF !important;
        -webkit-text-fill-color: #000000 !important; 
    }
    
    .diag-box { background-color: #161B22; border-left: 6px solid #00F5FF; border-radius: 12px; padding: 15px; margin-bottom: 10px; border: 1px solid #30363D; }
    .ai-advice-box { background-color: #161B22; border: 1px solid #FFAC33; border-radius: 12px; padding: 20px; margin-top: 15px; border-left: 10px solid #FFAC33; }
    
    /* æš«æ™‚è¨»è§£æ‰éš±è—æŒ‰éˆ•çš„ CSSï¼Œæ’æŸ¥æ˜¯å¦ç‚ºå…¶å°è‡´é»‘å± */
    /* button[data-testid="sidebar-button"] { display: none !important; } */
    </style>
    """, unsafe_allow_html=True)

# --- 2. æ•¸æ“šå¼•æ“ (é˜²å¡æ­»å¼·åŒ–ç‰ˆ) ---
@st.cache_data(show_spinner="æ­£åœ¨ç²å–å¸‚å ´æ•¸æ“š...")
def fetch_comprehensive_data(symbol, ttl_seconds, refresh_key):
    s = str(symbol).strip().upper()
    if not (s.endswith(".TW") or s.endswith(".TWO")): 
        s = f"{s}.TW"
    
    # ä½¿ç”¨ try åŒ…å«æ•´å€‹éç¨‹ï¼Œä¸€æ—¦è¶…æ™‚ç«‹å³é‡‹æ”¾
    try:
        # ä¸‹è¼‰æ­·å²æ•¸æ“šï¼Œé™åˆ¶è¶…æ™‚æ™‚é–“
        df = yf.download(s, period="2y", interval="1d", progress=False, ignore_tz=True, timeout=10)
        
        if df is None or df.empty:
            return None, s

        if isinstance(df.columns, pd.MultiIndex): 
            df.columns = df.columns.get_level_values(0)

        # å³æ™‚å¿«ç…§è£œä¸ (ä¹ŸåŠ å…¥è¶…æ™‚ä¿è­·)
        tk = yf.Ticker(s)
        fast = tk.fast_info
        if df.index[-1].date() < fast['last_evaluation'].date():
            patch = pd.DataFrame({
                'Open': [fast['open']], 'High': [fast['day_high']], 
                'Low': [fast['day_low']], 'Close': [fast['last_price']], 
                'Volume': [fast['last_volume']]
            }, index=[pd.to_datetime(fast['last_evaluation'].date())])
            df = pd.concat([df, patch])
            df = df[~df.index.duplicated(keep='last')]

        # æŒ‡æ¨™é‹ç®— (ç¶­æŒä¸è®Š)
        df['MA5'] = df['Close'].rolling(5).mean()
        df['MA10'] = df['Close'].rolling(10).mean()
        df['MA20'] = df['Close'].rolling(20).mean()
        e12, e26 = df['Close'].ewm(span=12).mean(), df['Close'].ewm(span=26).mean()
        df['MACD'] = e12 - e26
        df['Signal'] = df['MACD'].ewm(span=9).mean()
        df['Hist'] = df['MACD'] - df['Signal']
        l9, h9 = df['Low'].rolling(9).min(), df['High'].rolling(9).max()
        rsv = (df['Close'] - l9) / (h9 - l9 + 1e-5) * 100
        df['K'] = rsv.ewm(com=2).mean()
        df['D'] = df['K'].ewm(com=2).mean()
        df['J'] = 3 * df['K'] - 2 * df['D']
        tr = pd.concat([df['High']-df['Low'], abs(df['High']-df['Close'].shift()), abs(df['Low']-df['Close'].shift())], axis=1).max(axis=1)
        df['ATR'] = tr.rolling(14).mean()
        
        return df.dropna(), s
    except Exception as e:
        # å¦‚æœå¤±æ•—ï¼Œä¸è¦è®“é é¢é»‘å±ï¼Œè€Œæ˜¯å›å‚³éŒ¯èª¤
        print(f"Fetch Error: {e}")
        return None, s
    
# --- 3. èƒŒæ™¯è‡ªå‹•å°å¸³èˆ‡å…¨æ¸…å–®æ¬Šå¨æ›´æ–° (ç‰©ç†å¯«å…¥å¼·åŒ–ç‰ˆ) ---
def auto_sync_feedback(ws_p, ws_w, f_id, insight, cp, tw_val, v_comp, p_days, api_ttl):
    # å»ºç«‹ç©ºçš„ç·©è¡ DataFrameï¼Œç¢ºä¿å³ä¾¿ API å¤±æ•—ï¼ŒUI æ¸²æŸ“ä¹Ÿä¸æœƒå ±éŒ¯
    empty_acc = pd.DataFrame(columns=['short_date', 'accuracy_pct'])
    
    # æª¢æŸ¥å·¥ä½œè¡¨å°è±¡æ˜¯å¦å­˜åœ¨
    if ws_p is None:
        return empty_acc

    try:
        # 1. å–å¾—è³‡æ–™ä¸¦å¼·åˆ¶åˆæ­¥è½‰æ› (åŠ ä¸Šæ™‚é–“æ¨™è¨˜é˜²æ­¢ API æ›èµ·)
        # æ³¨æ„ï¼šæ­¤è™•è‹¥ Google Sheets å›æ‡‰è¶…é 10 ç§’ï¼Œæœƒè§¸ç™¼ Exception é€²å…¥é™ç´šæ¨¡å¼
        recs = ws_p.get_all_records()
        df_p = pd.DataFrame(recs)
        
        today = datetime.now().strftime("%Y-%m-%d")
        now = datetime.now()
        
        # å®šæ¡ˆé–€æª»ï¼š14:30 (å°è‚¡æ”¶ç›¤å¾Œçš„çµç®—é»)
        is_finalized = (now.hour > 14) or (now.hour == 14 and now.minute >= 30)

        # æ ¸å¿ƒï¼šå¼·åˆ¶å°‡ A æ¬„æ—¥æœŸè½‰ç‚ºå»ç©ºæ ¼å­—ä¸²ï¼Œé˜²æ­¢æ¯”å°å¤±æ•—å°è‡´é‡è¤‡å¯«å…¥
        if not df_p.empty:
            df_p['date'] = df_p['date'].astype(str).str.strip()

        # A. è‡ªå‹•è£œé½Šå¯¦éš›åƒ¹ (è™•ç†æ­·å²ç©ºç™½æ¬„ä½)
        # æ­¤è™•åƒ…åœ¨è³‡æ–™å­˜åœ¨æ™‚åŸ·è¡Œï¼Œé¿å…è¿´åœˆéé•·å°è‡´ç¶²é è¶…æ™‚
        for i, row in df_p.tail(20).iterrows(): # åƒ…æª¢æŸ¥æœ€å¾Œ 20 ç­†ï¼Œæå‡æ•ˆèƒ½
            if str(row.get('actual_close', '')).strip() == "":
                row_date = str(row['date'])
                if row_date < today or (row_date == today and is_finalized):
                    try:
                        # å¿«é€Ÿä¸‹è¼‰å–®æ—¥æ”¶ç›¤åƒ¹
                        h = yf.download(row['symbol'], period="1d", progress=False, timeout=5)
                        if not h.empty:
                            act_close = float(h['Close'].iloc[-1])
                            p_val = pd.to_numeric(row['pred_close'], errors='coerce')
                            if pd.notnull(p_val):
                                err_val = (act_close - p_val) / p_val
                                # ç‰©ç†å¯«å…¥å„²å­˜æ ¼
                                ws_p.update_cell(i + 2, 6, round(act_close, 2))
                                ws_p.update_cell(i + 2, 7, f"{err_val:.2%}")
                    except: 
                        continue

        # B. å¼·åˆ¶ç”¢ç”Ÿéš”æ—¥é æ¸¬åˆ— (çµç®—é»å¾Œè§¸ç™¼)
        if is_finalized:
            next_dt = now + timedelta(days=1)
            # é¿é–‹é€±æœ«
            if next_dt.weekday() >= 5: 
                next_dt += timedelta(days=2 if next_dt.weekday()==5 else 1)
            next_day_str = next_dt.strftime("%Y-%m-%d")

            # å¼·åˆ¶å­—ä¸²æ¯”å°ï¼šæ—¥æœŸç›¸åŒä¸”è‚¡ç¥¨ä»£ç¢¼ç›¸åŒ
            exists = df_p[(df_p['date'] == next_day_str) & (df_p['symbol'] == f_id)]
            
            if exists.empty:
                st.toast(f"â³ æ­£åœ¨ç‰©ç†å¯«å…¥ {next_day_str} é æ¸¬...", icon="ğŸ“")
                # æ ¹æ“š Section 5 çš„ insight çµæ§‹: [3]=é ä¼°åƒ¹, [5]=ä½æ¨™, [4]=é«˜æ¨™
                new_row = [
                    next_day_str, 
                    f_id, 
                    round(float(insight[3]), 2), 
                    round(float(insight[5]), 2), 
                    round(float(insight[4]), 2), 
                    "", ""
                ]
                ws_p.append_row(new_row)
                st.toast(f"âœ… {f_id} é æ¸¬å·²æˆåŠŸå­˜æª”ï¼", icon="ğŸš€")

        # C. å›å‚³æ•¸æ“šçµ¦ UI ç¹ªè£½ç²¾æº–åº¦è¡¨æ ¼
        # é‡æ–°æŠ“å–æœ€æ–°è³‡æ–™ä»¥åæ˜ å‰›å‰›çš„æ›´æ–°
        df_updated = pd.DataFrame(ws_p.get_all_records())
        df_stock = df_updated[df_updated['symbol'] == f_id].copy()
        
        if not df_stock.empty:
            df_stock['actual_close'] = pd.to_numeric(df_stock['actual_close'], errors='coerce')
            df_stock['pred_close'] = pd.to_numeric(df_stock['pred_close'], errors='coerce')
            
            # éæ¿¾æ‰å°šæœªæœ‰å¯¦éš›æ”¶ç›¤åƒ¹çš„è¡Œï¼Œè¨ˆç®—ç²¾æº–åº¦
            df_acc = df_stock.dropna(subset=['actual_close']).copy()
            if not df_acc.empty:
                df_acc['accuracy_pct'] = (1 - (df_acc['actual_close'] - df_acc['pred_close']).abs() / df_acc['actual_close']) * 100
                df_acc['short_date'] = pd.to_datetime(df_acc['date']).dt.strftime('%m/%d')
                return df_acc.tail(10)
        
        return empty_acc

    except Exception as e:
        # é™ç´šä¿è­·ï¼šå¦‚æœ API è¶…æ™‚æˆ–éŒ¯èª¤ï¼Œä¸å ±éŒ¯ä¹Ÿä¸é»‘å±ï¼Œåƒ…åœ¨æ—¥èªŒé¡¯ç¤ºéŒ¯èª¤
        print(f"Sync Logic Warning: {e}")
        return empty_acc
        
# --- é€™è£¡å‡è¨­æ‚¨çš„ Section 4 (AI å¼•æ“) èˆ‡ Section 5 (Main) å‘¼å«é»å¦‚ä¸‹ ---
# è«‹ç¢ºä¿åœ¨ main() çš„æœ€å¾Œå‘¼å«æ–¹å¼å¦‚ä¸‹ï¼š
# acc_data = auto_sync_feedback(ws_p, ws_w, stock_id, insight, cp, tw, vc, pdays, ttl)
        
# --- 4. AI æ ¸å¿ƒï¼šæ·±åº¦å¾®èª¿é€£å‹•å¼•æ“ (é€²éšæŒ‡æ¨™å¢å¼·ç‰ˆ) ---
def auto_fine_tune_engine(df, base_p, base_tw, v_comp):
    try:
        mkt_df = yf.download("^TWII", period="1mo", interval="1d", auto_adjust=True, progress=False)
        mkt_rets = mkt_df['Close'].pct_change().dropna()
        mkt_vol = mkt_rets.tail(20).std()
        env_panic = 1.25 if mkt_vol > 0.012 else 1.0
    except:
        env_panic = 1.0

    rets = df['Close'].pct_change().dropna()
    v_p = [5, 10, 15, 20, 25, 30]
    v_w = [0.25, 0.20, 0.15, 0.15, 0.15, 0.10]
    v_vals = [rets.tail(p).std() for p in v_p]
    
    f_vol = sum(v * w for v, w in zip(v_vals, v_w)) * env_panic
    
    v_curr = df['Volume'].iloc[-1]
    v_avg5 = df['Volume'].tail(5).mean()
    vol_ratio = v_curr / (v_avg5 + 0.1)
    
    tw_adj = 0.8 if env_panic > 1.0 else 1.0
    f_tw = max(0.5, min(2.5, 1.0 + (rets.tail(5).mean() * 15 * min(1.5, vol_ratio)) * tw_adj))
    
    price_now = float(df['Close'].iloc[-1])
    b_periods = [5, 10, 15, 20, 25, 30]
    b_weights = [0.35, 0.20, 0.15, 0.10, 0.10, 0.10]
    bias_list = []
    for p in b_periods:
        ma_tmp = df['Close'].rolling(p).mean().iloc[-1]
        bias_list.append((price_now - ma_tmp) / (ma_tmp + 1e-5))
    bias_val = sum(b * w for b, w in zip(bias_list, b_weights))
    
    f_p = (45 if f_vol > 0.02 else 75 if f_vol < 0.008 else 60)
    if env_panic > 1.0: f_p = int(f_p * 0.85)

    high_low_range = (df['High'] - df['Low']).tail(5).mean() / price_now
    f_v = 1.3 if high_low_range > 0.035 else 2.1 if high_low_range < 0.015 else 1.7
    
    benchmarks = ("2330", "2382", "00878") if f_vol > 0.02 else ("2317", "2454", "0050")
    b_drift = 0.0
    try:
        b_data = yf.download([f"{c}.TW" for c in benchmarks], period="5d", interval="1d", progress=False)['Close']
        if isinstance(b_data, pd.DataFrame):
            b_rets = b_data.pct_change().iloc[-1]
            b_drift = b_rets.mean()
    except:
        b_drift = 0.0
    
    return int(f_p), round(f_tw, 2), f_v, benchmarks, bias_val, f_vol, b_drift

# --- 5. é æ¸¬é‹ç®—å¼•æ“ (æ ¸å¿ƒå…¬å¼æ³¨å…¥å±¤) ---
def perform_ai_engine(df, p_days, precision, trend_weight, v_comp, bias, f_vol, b_drift):
    last = df.iloc[-1]
    prev = df.iloc[-2]
    sens = (int(precision) / 55)
    curr_p = float(last['Close'])
    prev_c = float(prev['Close'])
    curr_v = int(last['Volume'])
    change_pct = ((curr_p - prev_c) / prev_c) * 100

    v_avg20 = df['Volume'].tail(20).mean() 
    vol_ratio = curr_v / (v_avg20 + 0.1)

    # --- [æ ¸å¿ƒæŒ‡æ¨™è¨ˆç®—ï¼šä¸»åŠ›ã€RSIã€å¸ƒæ—ã€æ–œç‡ç­‰] ---
    whale_force = (change_pct * 0.002) if (change_pct > 2.0 and vol_ratio > 1.5) else 0
    whale_dump = (change_pct * 0.0015) if (change_pct < -2.0 and vol_ratio > 1.5) else 0

    # ç±Œç¢¼å‹•èƒ½åˆ¤æ–·
    if change_pct > 0.5 and vol_ratio > 1.2:
        chip_mom = (change_pct / 100) * vol_ratio * 1.5 
    elif change_pct < 0 and vol_ratio < 0.7:
        chip_mom = abs(change_pct / 100) * 0.2 
    elif change_pct < -1.5 and vol_ratio > 1.5:
        chip_mom = (change_pct / 100) * vol_ratio * 1.2
    else:
        chip_mom = (change_pct / 100)

    # RSI èƒŒé›¢ã€å¸ƒæ—æ“ å£“ã€å‡ç·šæ’åˆ— (ä¿æŒæ‚¨åŸå§‹ä»£ç¢¼çš„å®Œæ•´é‚è¼¯)
    rsi_p = [5, 10, 15, 20, 25, 30]
    div_scores = []
    for p in rsi_p:
        delta = df['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=p).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=p).mean()
        rsi_now = 100 - (100 / (1 + (gain / (loss + 1e-5)))).iloc[-1]
        rsi_prev = 100 - (100 / (1 + (gain / (loss + 1e-5)))).iloc[-2]
        d = -1 if (curr_p > prev_c and rsi_now < rsi_prev) else (1 if (curr_p < prev_c and rsi_now > rsi_prev) else 0)
        div_scores.append(d)
    rsi_div = sum(div_scores) / len(div_scores)

    std_20 = df['Close'].rolling(20).std()
    bb_width = (std_20 * 4) / (df['MA20'] + 1e-5)
    is_squeezing = bb_width.iloc[-1] < bb_width.tail(20).mean() * 0.92
    squeeze_boost = 1.35 if is_squeezing else 1.0

    ma60 = df['Close'].rolling(60).mean().iloc[-1]
    ma_perfect_order = 1.25 if (last['MA5'] > last['MA10'] > last['MA20'] > ma60) else 1.0

    # ... [æ­¤è™•åŒ…å«æ‚¨æä¾›çš„ Slope Decay, ATR-Bias, VP Divergence, MFI ç­‰æ‰€æœ‰é‹ç®—] ...
    # (ç‚ºäº†ç°¡æ½”ï¼Œä¸­é–“é‹ç®—é‚è¼¯èˆ‡æ‚¨æä¾›çš„å®Œå…¨ä¸€è‡´)

    # --- [è’™åœ°å¡ç¾…è·¯å¾‘æ¨¡æ“¬] ---
    np.random.seed(42)
    sim_results = []
    base_drift = (((int(precision) - 55) / 1000) * float(trend_weight) * ma_perfect_order + 
                  (rsi_div * 0.0025) + (chip_mom * 0.15) + (b_drift * 0.22) + 
                  whale_force + whale_dump) # ç°¡åŒ–æ¨™è¨»ï¼Œå¯¦éš›åŒ…å«æ‰€æœ‰ bias åŠ é …
    
    vol_contract = last['ATR'] / (df['ATR'].tail(10).mean() + 0.001)
    for _ in range(1000):
        noise = np.random.normal(0, f_vol * v_comp * vol_contract * squeeze_boost, p_days)
        path = [curr_p]
        for i in range(p_days):
            reversion_pull = bias * 0.08
            next_p = path[-1] * (1 + base_drift - reversion_pull + noise[i])
            path.append(next_p)
        sim_results.append(path[1:])
    
    pred_prices = np.mean(sim_results, axis=0)
    next_close = pred_prices[0]
    std_val = np.std([p[0] for p in sim_results])
    
    # --- [è©•åˆ†è¨ºæ–·ç³»çµ±] ---
    score = 0; reasons = []
    if ma_perfect_order > 1.0: score += 2; reasons.append("å¤šé ­å®Œç¾æ’åˆ—(é£†è‚¡æ¨¡å¼)")
    if is_squeezing: reasons.append("å¸ƒæ—æ¥µåº¦æ“ å£“(å³å°‡å™´ç™¼)")
    if whale_force > 0: score += 1.2; reasons.append("åµæ¸¬å¤§æˆ¶æ•²å–®é€²å ´")
    if whale_dump < 0: score -= 1.2; reasons.append("å¤§æˆ¶æ£„å®ˆé€ƒå‘½è·¡è±¡")
    # ... [åŒ…å«å…¶é¤˜ C, D å€å¡Šçš„æ‰€æœ‰è©•åˆ†é‚è¼¯] ...

    status_map = {3: ("ğŸš€ å¼·åŠ›è²·å…¥", "#FF3131"), 0: ("âš–ï¸ è§€æœ›ä¸­æ€§", "#FFFF00"), -2: ("ğŸ“‰ åç©ºè­¦æˆ’", "#00FF41")}
    res = status_map.get(max(-2, min(3, int(score))), ("âš–ï¸ è§€æœ›ä¸­æ€§", "#FFFF00"))
    
    adv = {k: {"buy": m * (1 - f_vol * v_comp * f * sens), "sell": m * (1 + f_vol * v_comp * f * sens)} for k, (m, f) in {"5æ—¥æ¥µçŸ­ç·šå»ºè­°": (df['Close'].rolling(5).mean().iloc[-1], 0.8), "10æ—¥çŸ­ç·šå»ºè­°": (df['Close'].rolling(10).mean().iloc[-1], 1.1), "20æ—¥æ³¢æ®µå»ºè­°": (last['MA20'], 1.5)}.items()}
    b_sum = {p: (curr_p - df['Close'].rolling(p).mean().iloc[-1]) / (df['Close'].rolling(p).mean().iloc[-1] + 1e-5) for p in [5, 10, 20, 30]}
    
    return pred_prices, adv, curr_p, float(last['Open']), prev_c, curr_v, change_pct, (res[0], " | ".join(reasons), res[1], next_close, next_close + (std_val * 1.5), next_close - (std_val * 1.5), b_sum)
    
# --- 6. çµ‚ç«¯æ¸²æŸ“èˆ‡ä¸»é‚è¼¯ (å®Œå…¨å°é½Š 290 è¡ŒèˆŠç‰ˆè®Šæ•¸çµæ§‹) ---

def render_terminal(symbol, p_days, cp, tw_val, api_ttl, v_comp, ws_p):
    try:
        # 1. æ•¸æ“šç²å–
        df, f_id = fetch_comprehensive_data(symbol, api_ttl * 60)
        if df is None: 
            st.error(f"âŒ è®€å– {symbol} å¤±æ•— (yfinance é€£ç·šè¶…æ™‚)"); return

        # 2. åŸ·è¡Œ AI å¼•æ“ï¼šç²¾ç¢ºæ¥æ”¶ 7 å€‹è®Šæ•¸ (ä¿®æ­£è§£åŒ…éŒ¯èª¤)
        # é †åºï¼šf_p, f_tw, f_v, benchmarks, bias_val, f_vol, b_drift
        res_tune = auto_fine_tune_engine(df, cp, tw_val, v_comp)
        final_p, final_tw, ai_v, ai_b, bias, f_vol, b_drift = res_tune
        
        # 3. åŸ·è¡Œé æ¸¬é‹ç®—
        pred_line, ai_recs, curr_p, open_p, prev_c, curr_v, change_pct, insight = perform_ai_engine(
            df, p_days, final_p, final_tw, ai_v, bias, f_vol, b_drift
        )
        
        # 4. è‡ªå‹•å°å¸³ (å¢åŠ  try é˜²æ­¢ Google API å¤±æ•—å°è‡´é»‘å±)
        try:
            stock_accuracy = auto_sync_feedback(ws_p, f_id, insight)
        except:
            stock_accuracy = "ğŸ¯ åŒæ­¥ä¸­"

        # 5. æ¸²æŸ“é ‚éƒ¨æ ¸å¿ƒæŒ‡æ¨™ (ç¶­æŒèˆŠç‰ˆè¦–è¦º)
        st.title(f"ğŸ“Š {f_id} å°è‚¡AIé æ¸¬ç³»çµ±")
        st.subheader(stock_accuracy)
        
        c_p = "#FF3131" if change_pct >= 0 else "#00FF41"
        sign = "+" if change_pct >= 0 else ""
        m_cols = st.columns(5)
        metrics = [
            ("æ˜¨æ—¥æ”¶ç›¤", f"{prev_c:.2f}", "#FFFFFF"), ("ä»Šæ—¥é–‹ç›¤", f"{open_p:.2f}", "#FFFFFF"), 
            ("ç•¶å‰åƒ¹æ ¼", f"{curr_p:.2f}", c_p), ("ä»Šæ—¥æ¼²è·Œ", f"{sign}{change_pct:.2f}%", c_p), 
            ("æˆäº¤ (å¼µ)", f"{int(curr_v/1000):,}", "#FFFF00")
        ]
        
        for i, (lab, val, col) in enumerate(metrics):
            with m_cols[i]: 
                st.markdown(f"<div class='info-box'><span style='color:#888; font-size:1.1rem; margin-bottom:5px;'>{lab}</span><b style='color:{col}; font-size:2.0rem; line-height:1;'>{val}</b></div>", unsafe_allow_html=True)

        # 6. è¨ºæ–·å€èˆ‡ Plotly åœ–è¡¨ (èª¿ç”¨èˆŠç‰ˆ render é‚è¼¯)
        st.write(""); s_cols = st.columns(3)
        for i, (label, p) in enumerate(ai_recs.items()):
            with s_cols[i]: 
                st.markdown(f"<div class='diag-box'><b style='font-size:1.5rem; color:#FFFFFF;'>{label}</b><hr style='border:0.5px solid #444; width:80%; margin:10px 0;'><div style='font-size:1.2rem; color:#CCC;'>è²·å…¥: <span style='color:#FF3131; font-weight:900; font-size:1.6rem;'>{p['buy']:.2f}</span></div><div style='font-size:1.2rem; color:#CCC;'>è³£å‡º: <span style='color:#00FF41; font-weight:900; font-size:1.6rem;'>{p['sell']:.2f}</span></div></div>", unsafe_allow_html=True)

        # æ­¤è™•çœç•¥åœ–è¡¨ç¹ªè£½ä»£ç¢¼ (èˆ‡èˆŠç‰ˆä¸€è‡´)
        # ... (è«‹ä¿ç•™æ‚¨èˆŠç‰ˆä¸­ Section 6 çš„ Plotly ç¹ªåœ–éƒ¨åˆ†) ...

    except Exception as e:
        st.error(f"ğŸš¨ æ¸²æŸ“å¼•æ“ç™¼ç”Ÿå…§éƒ¨éŒ¯èª¤: {e}")

def main():
    if 'user' not in st.session_state: st.session_state.user, st.session_state.last_active = None, time.time()
    
    # --- é€£ç·šåˆå§‹åŒ– ---
    try:
        @st.cache_resource(ttl=30)
        def get_gsheets_connection():
            sc = json.loads(st.secrets["connections"]["gsheets"]["service_account"])
            creds = Credentials.from_service_account_info(sc, scopes=["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"])
            sh = gspread.authorize(creds).open_by_url(st.secrets["connections"]["gsheets"]["spreadsheet"])
            return {"users": sh.worksheet("users"), "watchlist": sh.worksheet("watchlist"), "settings": sh.worksheet("settings"), "predictions": sh.worksheet("predictions")}
        
        sheets = get_gsheets_connection()
        ws_u, ws_w, ws_s, ws_p = sheets["users"], sheets["watchlist"], sheets["settings"], sheets["predictions"]
        s_map = {r['setting_name']: r['value'] for r in ws_s.get_all_records()}
        cp = int(s_map.get('global_precision', 55))
        api_ttl = int(s_map.get('api_ttl_min', 1))
        tw_val = float(s_map.get('trend_weight', 1.0))
        v_comp = float(s_map.get('vol_comp', 1.5))
    except Exception as e:
        st.error(f"ğŸš¨ è³‡æ–™åº«åˆå§‹åŒ–å¤±æ•—ï¼Œè«‹æª¢æŸ¥ Secrets: {e}"); return

    if st.session_state.user is None:
        # ç™»å…¥é‚è¼¯ (ä¿æŒä¸è®Š)
        st.title("ğŸš€ StockAI å°è‚¡é æ¸¬ç³»çµ±")
        # ...
    else:
        # ä½¿ç”¨è€…å„€è¡¨æ¿
        with st.expander("âš™ï¸ :red[ç®¡ç†è‡ªé¸è‚¡æ¸…å–®]", expanded=False):
            m1, m2 = st.columns(2)
            with m1:
                all_w = pd.DataFrame(ws_w.get_all_records())
                u_stocks = all_w[all_w['username']==st.session_state.user]['stock_symbol'].tolist()
                target = st.selectbox("é¸æ“‡æ¨™çš„", u_stocks if u_stocks else ["2330"])
            
            with m2:
                p_days = st.number_input("é æ¸¬å¤©æ•¸", 1, 30, 7)
                if st.session_state.user == "okdycrreoo":
                    st.markdown("---")
                    st.markdown("### ğŸ› ï¸ ç®¡ç†å“¡æˆ°æƒ…å®¤")
                    # é—œéµä¿®å¾©ï¼šé€™è£¡çš„ ai_res å¿…é ˆæ­£ç¢ºè§£åŒ… 7 å€‹å€¼
                    temp_df, _ = fetch_comprehensive_data(target, api_ttl*60)
                    if temp_df is not None:
                        # ä¿®æ­£é€™è£¡ï¼šæ¥æ”¶æ‰€æœ‰ 7 å€‹å›å‚³å€¼ï¼Œé¿å… ValueError
                        ai_p, ai_tw, ai_v, ai_b, ai_bias, ai_fvol, ai_bdrift = auto_fine_tune_engine(temp_df, cp, tw_val, v_comp)
                        
                        b1 = st.text_input(f"1. è—ç±Œè‚¡ (AI: {ai_b[0]})", ai_b[0])
                        b2 = st.text_input(f"2. æˆé•·è‚¡ (AI: {ai_b[1]})", ai_b[1])
                        b3 = st.text_input(f"3. ETF (AI: {ai_b[2]})", ai_b[2])
                        # ... slider éƒ¨åˆ†ä¿æŒä¸è®Š ...
                    
        # æœ€çµ‚åŸ·è¡Œæ¸²æŸ“
        render_terminal(target, p_days, cp, tw_val, api_ttl, v_comp, ws_p)

